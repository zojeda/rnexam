---
title: "Examen Resuelto"
author: "Ojeda, Zacarías F."
date: "2/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(tidyverse)
library(caret)
```


## Construcción del modelo


Carga de datos: 

```{r message=FALSE}
winequality <- read_csv("data/winequality.csv")
```

Se configura la semilla aleatoria para hacer repetible los resultados
```{r}
set.seed(1)
```


Creando particiones de datos para training y testing

```{r}


inTraining <- createDataPartition(winequality$quality, p = .75, list = FALSE)
training <- winequality[ inTraining,]
testing  <- winequality[-inTraining,]
```


El modo de entrenamiento se realizará utilizando K-fold cross-validation, en este caso 10 veces, 10 *folds* 

```{r}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10)
```


Utilizaremos Multi-Layer Perceptron como modelo predictivo
```{r}
nn1 <- train(quality ~ ., 
             data = training, 
             method = "mlp", 
             trControl = fitControl,
             preProc = c("center", "scale"),
             tuneGrid = expand.grid(size = 1:8),
             verbose = FALSE)
nn1
```



```{r}
prediccionNN1 <- predict(nn1, newdata = testing) %>% round()
reales <- testing$quality

RMSE(prediccionNN1, reales)
```
Es posible observar que la raiz del error cuadrático medio se aproxima al modelo seleccionado luego de la optimización de hiperparámetros. Es decir que no se observa sobreentrenamiento.

```{r}
table(abs(prediccionNN1 - reales))
```



Resulta también interesante intentar con una red Multi-Layer Perceptron, con múltiples capas ocultas.


```{r}
mlpGrid = expand.grid(layer1 = 1:10,
                       layer2 = 1:10,
                       layer3 = 1:10)

nn2 = train(quality ~ ., 
             data = training,  
                method = "mlpML", 
                preProc =  c('center', 'scale', 'knnImpute', 'pca'),
                trControl = fitControl,
                tuneGrid = mlpGrid)
nn2
```


```{r}
prediccionNN2 <- predict(nn2, newdata = testing) %>% round()
reales <- testing$quality

RMSE(prediccionNN2, reales)
```

